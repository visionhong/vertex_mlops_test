# Copyright 2023 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#            http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#############################################################################
# CI/CD steps for Cloud Build to test and deploy a TFX pipeline to Vertex AI.
#############################################################################

# Access the id_github file from Secret Manager, and setup SSH
steps:
- name: 'gcr.io/cloud-builders/git'
  secretEnv: ['SSH_KEY']
  entrypoint: 'bash'
  args:
  - -c
  - |
    echo "$$SSH_KEY" >> /root/.ssh/id_rsa
    chmod 400 /root/.ssh/id_rsa
    ssh-keyscan -t rsa github.com > /root/.ssh/known_hosts
  volumes:
  - name: 'ssh'
    path: /root/.ssh
  id: 'Prepare git keys'

# Clone the repository.
- name: 'gcr.io/cloud-builders/git'
  args: ['clone', '--single-branch', '--branch',
         '$_BRANCH', '$_REPO_URL',
         '--depth', '1',
         '--verbose']
  volumes:
  - name: 'ssh'
    path: /root/.ssh
  id: 'Clone Repository'
  waitFor: ['Prepare git keys']
  

# Run datasource_utils unit tests.
- name: '$_CICD_IMAGE_URI'
  entrypoint: 'pytest'
  args: ['src/tests/datasource_utils_tests.py', '-s']
  dir: '$_WORKDIR'
  env: 
  - 'PROJECT=$_PROJECT'  
  - 'BQ_LOCATION=$_BQ_LOCATION'
  - 'BQ_DATASET_NAME=$_BQ_DATASET_NAME'
  - 'ML_TABLE=$_ML_TABLE'  
  id: 'Unit Test Datasource Utils'
  waitFor: ['Clone Repository']


# Run model unit tests.
- name: '$_CICD_IMAGE_URI'
  entrypoint: 'pytest'
  args: ['src/tests/model_tests.py', '-s']
  dir: '$_WORKDIR'
  id: 'Unit Test Model'
  waitFor: ['Clone Repository']
  timeout: 1800s


# Test e2e pipeline using local runner.
- name: '$_CICD_IMAGE_URI'
  entrypoint: 'pytest'
  args: ['src/tests/pipeline_deployment_tests.py::test_e2e_pipeline', '-s']
  dir: '$_WORKDIR'
  env: 
  - 'PROJECT=$_PROJECT'  
  - 'REGION=$_REGION'
  - 'MODEL_DISPLAY_NAME=$_MODEL_DISPLAY_NAME'
  - 'VERTEX_DATASET_NAME=$_VERTEX_DATASET_NAME'  
  - 'GCS_LOCATION=$_TEST_GCS_LOCATION'
  - 'TRAIN_LIMIT=$_CI_TRAIN_LIMIT'
  - 'TEST_LIMIT=$_CI_TEST_LIMIT'  
  - 'UPLOAD_MODEL=$_CI_UPLOAD_MODEL'
  - 'ACCURACY_THRESHOLD=$_CI_ACCURACY_THRESHOLD'
  id: 'Local Test E2E Pipeline'
  waitFor: ['Clone Repository']
  timeout: 1800s

# Compile the pipeline.
- name: '$_CICD_IMAGE_URI'
  entrypoint: 'python'
  args: ['build/utils.py',
          '--mode', 'compile-pipeline',
          '--pipeline-name', '$_PIPELINE_NAME'
          ]
  dir: '$_WORKDIR'
  env: 
  - 'PROJECT=$_PROJECT'  
  - 'REGION=$_REGION'
  - 'MODEL_DISPLAY_NAME=$_MODEL_DISPLAY_NAME'
  - 'VERTEX_DATASET_NAME=$_VERTEX_DATASET_NAME'  
  - 'GCS_LOCATION=$_GCS_LOCATION'
  - 'DATAFLOW_IMAGE_URI=$_DATAFLOW_IMAGE_URI'
  - 'TFX_IMAGE_URI=$_TFX_IMAGE_URI' 
  - 'BEAM_RUNNER=$_BEAM_RUNNER'
  - 'TRAINING_RUNNER=$_TRAINING_RUNNER'
  - 'SERVICE_ACCOUNT=$_SERVICE_ACCOUNT'
  - 'SUBNETWORK=$_SUBNETWORK'
  - 'ACCURACY_THRESHOLD=$_CI_ACCURACY_THRESHOLD'
  
  id: 'Compile Pipeline'
  waitFor: ['Local Test E2E Pipeline', 'Unit Test Datasource Utils', 'Unit Test Model']
  
  
# Upload compiled pipeline to GCS.
- name: 'gcr.io/cloud-builders/gsutil'
  args: ['cp', '$_PIPELINE_NAME.json', '$_PIPELINES_STORE']
  dir: '$_WORKDIR'
  id:  'Upload Pipeline to GCS'
  waitFor: ['Compile Pipeline']
  

serviceAccount: 'projects/$_PROJECT/serviceAccounts/$_SERVICE_ACCOUNT'
logsBucket: '$_GCS_BUCKET'
timeout: 7200s
substitutions:
  _REPO_URL: git@github.com:${github_org}/${github_repo}
  _BRANCH: ${github_branch}
  _REGION: ${region}
  _PROJECT: ${project_id}
  _GCS_BUCKET: ${project_id}_cloudbuild/logs
  _CICD_IMAGE_URI: '${docker_repo}/cicd-tfx:latest'
  _DATAFLOW_IMAGE_URI: '${docker_repo}/dataflow:latest'
  _TFX_IMAGE_URI: '${docker_repo}/vertex:latest'
  _GCS_LOCATION: 'gs://${bucket_name}/creditcards/'
  _TEST_GCS_LOCATION: 'gs://${bucket_name}/creditcards/e2e_tests'
  _BQ_LOCATION: ${region}
  _BQ_DATASET_NAME: creditcards
  _ML_TABLE: creditcards_ml
  _VERTEX_DATASET_NAME: creditcards
  _MODEL_DISPLAY_NAME: creditcards-classifier-v02
  _CI_TRAIN_LIMIT: '1000'
  _CI_TEST_LIMIT: '100'
  _CI_UPLOAD_MODEL: '0'
  _CI_ACCURACY_THRESHOLD: '-0.1'
  _BEAM_RUNNER: DataflowRunner
  _TRAINING_RUNNER: vertex
  _PIPELINE_NAME: creditcards-classifier-v02-train-pipeline
  _PIPELINES_STORE: gs://${bucket_name}/creditcards/compiled_pipelines/
  _SUBNETWORK: ${subnetwork}
  _SERVICE_ACCOUNT: ${sa_mlops}
  _WORKDIR: ${github_repo}
options:
  machineType: 'E2_HIGHCPU_8'

availableSecrets:
  secretManager:
  - versionName: projects/${project_id}/secrets/github-key/versions/latest
    env: 'SSH_KEY'
